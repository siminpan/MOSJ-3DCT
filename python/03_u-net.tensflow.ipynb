{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.measure\n",
    "# import pydicom\n",
    "import vtk\n",
    "from vtk.util import numpy_support\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "os.chdir('C:/Users/span/Documents/CNN/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = '02_data/train_image_0255/'\n",
    "path2 = '02_data/train_mask_0255/'\n",
    "path3 = '02_data/val_image_0255/'\n",
    "path4 = '02_data/val_mask_0255/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(a=1024, version=2)\n",
    "list1 = os.listdir(str(path3)+'image/')\n",
    "list2 = random.sample(list1, k=64)\n",
    "\n",
    "list3 = os.listdir(str(path4)+'seg/')\n",
    "list4 = random.sample(list1, k=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list2:\n",
    "    os.replace(r'C:/Users/span/Documents/CNN/'+path3+'image/'+ i, r'C:/Users/span/Documents/CNN/'+path1+'image/'+ i)\n",
    "for i in list3:\n",
    "    os.replace(r'C:/Users/span/Documents/CNN/'+path4+'seg/'+ i, r'C:/Users/span/Documents/CNN/'+path2+'seg/'+ i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True\n",
    ")\n",
    "        \n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only 0 and 255 in seg\n",
    "path1 = \"02_data/train_image_0255/\"\n",
    "path2 = \"02_data/train_mask_0255/\"\n",
    "path3 = \"02_data/val_image_0255/\"\n",
    "path4 = \"02_data/val_mask_0255/\"\n",
    "\n",
    "# # scale to 255 in val\n",
    "# path1 = \"02_data/train_image_re255/\"\n",
    "# path2 = \"02_data/train_mask_re255/\"\n",
    "# path3 = \"02_data/val_image_re255/\"\n",
    "# path4 = \"02_data/val_mask_re255/\"\n",
    "\n",
    "batch_size1 = 16\n",
    "\n",
    "train_image_generator = train_datagen.flow_from_directory(\n",
    "    path1,\n",
    "    color_mode = \"grayscale\",\n",
    "    batch_size = batch_size1 #NORMALLY 4/8/16/32\n",
    ")\n",
    "\n",
    "train_mask_generator = train_datagen.flow_from_directory(\n",
    "    path2,\n",
    "    color_mode = \"grayscale\",\n",
    "    batch_size = batch_size1 #NORMALLY 4/8/16/32\n",
    ")\n",
    "\n",
    "val_image_generator = val_datagen.flow_from_directory(\n",
    "    path3,\n",
    "    color_mode = \"grayscale\",\n",
    "    batch_size = batch_size1 #NORMALLY 4/8/16/32\n",
    ")\n",
    "\n",
    "\n",
    "val_mask_generator = val_datagen.flow_from_directory(\n",
    "    path4,\n",
    "    color_mode = \"grayscale\",\n",
    "    batch_size = batch_size1 #NORMALLY 4/8/16/32\n",
    ")\n",
    "\n",
    "train_generator = zip(train_image_generator, train_mask_generator)\n",
    "val_generator = zip(val_image_generator, val_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = (“<Copied path>”)\n",
    "IMAGE_SHAPE = (256, 256)\n",
    "TRAINING_DATA_DIR = str(data_root)\n",
    "datagen_kwargs = dict(rescale=1./255, validation_split=.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "TRAINING_DATA_DIR,\n",
    "subset=”validation”,\n",
    "shuffle=True,\n",
    "target_size=IMAGE_SHAPE\n",
    ")\n",
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(**datagen_kwargs)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "TRAINING_DATA_DIR,\n",
    "subset=”training”,\n",
    "shuffle=True,\n",
    "target_size=IMAGE_SHAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.examples.tensorflow_examples.models.pix2pix import pix2pix\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "import keras\n",
    "# from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, Input\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:/Users/span/Documents/CNN/date_oxford/')\n",
    "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(input_image, input_mask):\n",
    "  input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "  input_mask -= 1\n",
    "  return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def load_image_train(datapoint):\n",
    "  input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
    "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
    "\n",
    "  if tf.random.uniform(()) > 0.5:\n",
    "    input_image = tf.image.flip_left_right(input_image)\n",
    "    input_mask = tf.image.flip_left_right(input_mask)\n",
    "\n",
    "  input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "  return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_test(datapoint):\n",
    "  input_image = tf.image.resize(datapoint['image'], (128, 128))\n",
    "  input_mask = tf.image.resize(datapoint['segmentation_mask'], (128, 128))\n",
    "\n",
    "  input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "  return input_image, input_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LENGTH = info.splits['train'].num_examples\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 1000\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test = dataset['test'].map(load_image_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list):\n",
    "  plt.figure(figsize=(15, 15))\n",
    "\n",
    "  title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "\n",
    "  for i in range(len(display_list)):\n",
    "    plt.subplot(1, len(display_list), i+1)\n",
    "    plt.title(title[i])\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "    plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in train.take(1):\n",
    "  sample_image, sample_mask = image, mask\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 2\n",
    "cross_tower_ops = tf.distribute.HierarchicalCopyAllReduce(num_packs=num_gpus)\n",
    "strategy = tf.distribute.MirroredStrategy(cross_device_ops=cross_tower_ops)\n",
    "with strategy.scope():\n",
    "    base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n",
    "    # Use the activations of these layers\n",
    "    layer_names = [\n",
    "    'block_1_expand_relu',   # 64x64\n",
    "    'block_3_expand_relu',   # 32x32\n",
    "    'block_6_expand_relu',   # 16x16\n",
    "    'block_13_expand_relu',  # 8x8\n",
    "    'block_16_project',      # 4x4\n",
    "    ]\n",
    "    layers = [base_model.get_layer(name).output for name in layer_names]\n",
    "    # Create the feature extraction model\n",
    "    down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
    "    down_stack.trainable = False\n",
    "    up_stack = [\n",
    "        pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
    "        pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
    "        pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
    "        pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
    "    ]\n",
    "    def unet_model(output_channels):\n",
    "        inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
    "        x = inputs\n",
    "        skips = down_stack(x)\n",
    "        x = skips[-1]\n",
    "        skips = reversed(skips[:-1])\n",
    "        for up, skip in zip(up_stack, skips):\n",
    "            x = up(x)\n",
    "            concat = tf.keras.layers.Concatenate()\n",
    "            x = concat([x, skip])\n",
    "            last = tf.keras.layers.Conv2DTranspose(\n",
    "                output_channels, 3, strides=2,\n",
    "                padding='same')  #64x64 -> 128x128\n",
    "            x = last(x)\n",
    "            return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)\n",
    "\n",
    "# Use the activations of these layers\n",
    "layer_names = [\n",
    "    'block_1_expand_relu',   # 64x64\n",
    "    'block_3_expand_relu',   # 32x32\n",
    "    'block_6_expand_relu',   # 16x16\n",
    "    'block_13_expand_relu',  # 8x8\n",
    "    'block_16_project',      # 4x4\n",
    "]\n",
    "layers = [base_model.get_layer(name).output for name in layer_names]\n",
    "\n",
    "# Create the feature extraction model\n",
    "down_stack = tf.keras.Model(inputs=base_model.input, outputs=layers)\n",
    "\n",
    "down_stack.trainable = False\n",
    "\n",
    "up_stack = [\n",
    "        pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
    "        pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
    "        pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
    "        pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(output_channels):\n",
    "  inputs = tf.keras.layers.Input(shape=[128, 128, 3])\n",
    "  x = inputs\n",
    "\n",
    "  # Downsampling through the model\n",
    "  skips = down_stack(x)\n",
    "  x = skips[-1]\n",
    "  skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling and establishing the skip connections\n",
    "  for up, skip in zip(up_stack, skips):\n",
    "    x = up(x)\n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "    x = concat([x, skip])\n",
    "\n",
    "  # This is the last layer of the model\n",
    "  last = tf.keras.layers.Conv2DTranspose(\n",
    "      output_channels, 3, strides=2,\n",
    "      padding='same')  #64x64 -> 128x128\n",
    "\n",
    "  x = last(x)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet_model(OUTPUT_CHANNELS)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "  pred_mask = pred_mask[..., tf.newaxis]\n",
    "  return pred_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(dataset=None, num=1):\n",
    "  if dataset:\n",
    "    for image, mask in dataset.take(num):\n",
    "      pred_mask = model.predict(image)\n",
    "      display([image[0], mask[0], create_mask(pred_mask)])\n",
    "  else:\n",
    "    display([sample_image, sample_mask,\n",
    "             create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    clear_output(wait=True)\n",
    "    show_predictions()\n",
    "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "VAL_SUBSPLITS = 5\n",
    "VALIDATION_STEPS = info.splits['test'].num_examples//BATCH_SIZE//VAL_SUBSPLITS\n",
    "\n",
    "model_history = model.fit(train_dataset, epochs=EPOCHS,\n",
    "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                          validation_steps=VALIDATION_STEPS,\n",
    "                          validation_data=test_dataset,\n",
    "                          callbacks=[DisplayCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "epochs = range(EPOCHS)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions(test_dataset, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutiple GPU (less auc?)\n",
    "\n",
    "num_gpus = 2\n",
    "def get_model(optimizer, loss_metric, metrics, lr=1e-3):\n",
    "    cross_tower_ops = tf.distribute.HierarchicalCopyAllReduce(num_packs=num_gpus)\n",
    "    strategy = tf.distribute.MirroredStrategy(cross_device_ops=cross_tower_ops)\n",
    "#     strategy = tf.distribute.MirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        inputs = keras.Input((sample_width, sample_height, 1))\n",
    "        conv1 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='SAME')(inputs)\n",
    "        conv1 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='SAME')(conv1)\n",
    "        conv1 = tf.reshape(conv1, tf.shape(conv1))\n",
    "        pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        drop1 = keras.layers.Dropout(0.5)(pool1)\n",
    "\n",
    "        conv2 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(drop1)\n",
    "        conv2 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(conv2)\n",
    "        conv2 = tf.reshape(conv2, tf.shape(conv2))\n",
    "        pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "        drop2 = keras.layers.Dropout(0.5)(pool2)\n",
    "\n",
    "        conv3 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(drop2)\n",
    "        conv3 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(conv3)\n",
    "        conv3 = tf.reshape(conv3, tf.shape(conv3))\n",
    "        pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "        drop3 = keras.layers.Dropout(0.3)(pool3)\n",
    "\n",
    "        conv4 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(drop3)\n",
    "        conv4 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(conv4)\n",
    "        conv4 = tf.reshape(conv4, tf.shape(conv4))\n",
    "        pool4 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "        drop4 = keras.layers.Dropout(0.3)(pool4)\n",
    "\n",
    "        conv5 = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='SAME')(drop4)\n",
    "        conv5 = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='SAME')(conv5)\n",
    "        conv5 = tf.reshape(conv5, tf.shape(conv5))\n",
    "    \n",
    "        conv5u = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(conv5)\n",
    "        conv5u = tf.reshape(conv5u, tf.shape(conv5u))\n",
    "        up6 = keras.layers.concatenate([conv5u, conv4], axis=3)\n",
    "        conv6 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(up6)\n",
    "        conv6 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(conv6)\n",
    "        conv6 = tf.reshape(conv6, tf.shape(conv6))\n",
    "    \n",
    "        conv6u = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(conv6)\n",
    "        conv6u = tf.reshape(conv6u, tf.shape(conv6u))\n",
    "        up7 = keras.layers.concatenate([conv6u, conv3], axis=3)\n",
    "        conv7 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(up7)\n",
    "        conv7 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(conv7)\n",
    "        conv7 = tf.reshape(conv7, tf.shape(conv7))\n",
    "    \n",
    "        conv7u = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(conv7)\n",
    "        conv7u = tf.reshape(conv7u, tf.shape(conv7u))\n",
    "        up8 = keras.layers.concatenate([conv7u, conv2], axis=3)\n",
    "        conv8 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(up8)\n",
    "        conv8 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(conv8)\n",
    "        conv8 = tf.reshape(conv8, tf.shape(conv8))\n",
    "    \n",
    "        conv8u = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(conv8)\n",
    "        conv8u = tf.reshape(conv8u, tf.shape(conv8u))\n",
    "        up9 = keras.layers.concatenate([conv8u, conv1], axis=3)\n",
    "        conv9 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='SAME')(up9)\n",
    "        conv9 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='SAME')(conv9)\n",
    "        conv9 = tf.reshape(conv9, tf.shape(conv9))\n",
    "\n",
    "        conv10 = keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "        conv10 = tf.reshape(conv10, tf.shape(conv10))\n",
    "\n",
    "        model = keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "        model.compile(optimizer=optimizer(lr=lr), loss=loss_metric, metrics=metrics)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "# Dice Coefficient to work with Tensorflow\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "# Dice Coefficient to work outside Tensorflow\n",
    "def dice_coef_2(y_true, y_pred):\n",
    "    side = len(y_true[0])\n",
    "    y_true_f = y_true.reshape(side*side)\n",
    "    y_pred_f = y_pred.reshape(side*side)\n",
    "    intersection = sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (sum(y_true_f) + sum(y_pred_f) + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_width = 256\n",
    "sample_height = 256\n",
    "\n",
    "model = get_model(optimizer=tf.keras.optimizers.Adam, loss_metric=dice_coef_loss, metrics=['AUC', dice_coef], lr=1e-6)\n",
    "# 'AUC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()\n",
    "tf.keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historyTF = model.fit(\n",
    "#     train_generator, \n",
    "#     batch_size=4, \n",
    "#     epochs=10, \n",
    "#     validation_data = \n",
    "#     (val_image_generator,\n",
    "#      val_mask_generator)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit the keras model on the dataset\n",
    "# historyKe = model.fit(train_image_generator, train_mask_generator, epochs=150, batch_size=10)\n",
    "\n",
    "# train_generator = zip(train_image_generator, train_mask_generator)\n",
    "# val_generator = zip(val_image_generator, val_mask_generator)\n",
    "\n",
    "# from keras import backend as K\n",
    "\n",
    "# historyTF = model.fit(train_generator, epochs=10, validation_data=val_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='auc', patience=5)\n",
    "\n",
    "ACCURACY_THRESHOLD = 0.95\n",
    "class myCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        if(logs.get('auc') > ACCURACY_THRESHOLD):\n",
    "            print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD*100))\n",
    "            self.model.stop_training = True\n",
    "\n",
    "NO_OF_EPOCHS = 300\n",
    "\n",
    "NO_OF_TRAINING_IMAGES = len(os.listdir('02_data/train_image_0255/image/'))\n",
    "NO_OF_VAL_IMAGES = len(os.listdir('02_data/val_image_0255/image/'))\n",
    "\n",
    "# NO_OF_TRAINING_IMAGES = len(os.listdir('02_data/train_image_re255/image/'))\n",
    "# NO_OF_VAL_IMAGES = len(os.listdir('02_data/val_image_re255/image/'))\n",
    "\n",
    "BATCH_SIZE = batch_size1\n",
    "\n",
    "results = model.fit(train_generator, \n",
    "                    epochs=NO_OF_EPOCHS, \n",
    "                    steps_per_epoch=(NO_OF_TRAINING_IMAGES//BATCH_SIZE), \n",
    "                    validation_data=val_generator, \n",
    "                    validation_steps=(NO_OF_VAL_IMAGES//BATCH_SIZE),\n",
    "                    callbacks=myCallback() #[callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('03_model/Model_ep200_23.32.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir saved_model\n",
    "# model.save('03_model/saved_model/my_model_ep100') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(results.history['auc'])\n",
    "plt.plot(results.history['val_auc'])\n",
    "plt.title('model auc')\n",
    "plt.ylabel('auc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "  pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "  pred_mask = pred_mask[..., tf.newaxis]\n",
    "  return pred_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(dataset=None, num=1):\n",
    "  if dataset:\n",
    "    for image, mask in dataset.take(num):\n",
    "      pred_mask = model.predict(image)\n",
    "      display([image[0], mask[0], create_mask(pred_mask)])\n",
    "  else:\n",
    "    display([sample_image, sample_mask,\n",
    "             create_mask(model.predict(sample_image[tf.newaxis, ...]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# img0 = Image.fromarray(val_image_generator[3].astype(np.uint8), mode = \"L\")\n",
    "\n",
    "im = Image.new('L', (256, 256))\n",
    "im.putdata(val_image_generator[5])\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_as_tuple = next(val_image_generator)\n",
    "\n",
    "samples_to_predict = np.array(dataset_as_tuple[0])\n",
    "samples_to_predict2 = (((samples_to_predict - samples_to_predict.min()) / (samples_to_predict.max() - samples_to_predict.min())) * 255.9).astype(np.uint8)\n",
    "plt.imshow(samples_to_predict2[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(dataset_as_tuple[0])\n",
    "samples_to_predict3 = np.array(predictions[0])\n",
    "# samples_to_predict4 = (((samples_to_predict3 - samples_to_predict3.min()) / (samples_to_predict3.max() - samples_to_predict3.min())) * 255.9).astype(np.uint8)\n",
    "plt.imshow(samples_to_predict3[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_to_predict5 = samples_to_predict3.copy()\n",
    "samples_to_predict5[samples_to_predict5 >= np.percentile(samples_to_predict5, 95)] = 255\n",
    "samples_to_predict5[samples_to_predict5 != 255 ] = 0\n",
    "plt.imshow(samples_to_predict5[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_as_tuple = next(val_mask_generator)\n",
    "\n",
    "samples_to_predict = np.array(dataset_as_tuple[0])\n",
    "samples_to_predict2 = (((samples_to_predict - samples_to_predict.min()) / (samples_to_predict.max() - samples_to_predict.min())) * 255.9).astype(np.uint8)\n",
    "plt.imshow(samples_to_predict2[0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_to_predict4[150,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1 = np.array(dataset_as_tuple[0])[0,:,:]\n",
    "plt.imshow(a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a1.max(),a1.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
