{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "def get_model(optimizer, loss_metric, metrics, lr=1e-3):\n",
    "    inputs = keras.Input((sample_width, sample_height, 1))\n",
    "    conv1 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='SAME')(inputs)\n",
    "    conv1 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='SAME')(conv1)\n",
    "    pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    drop1 = keras.layers.Dropout(0.5)(pool1)\n",
    "\n",
    "    conv2 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(drop1)\n",
    "    conv2 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(conv2)\n",
    "    pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    drop2 = keras.layers.Dropout(0.5)(pool2)\n",
    "\n",
    "    conv3 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(drop2)\n",
    "    conv3 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(conv3)\n",
    "    pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    drop3 = keras.layers.Dropout(0.3)(pool3)\n",
    "\n",
    "    conv4 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(drop3)\n",
    "    conv4 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(conv4)\n",
    "    pool4 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    drop4 = keras.layers.Dropout(0.3)(pool4)\n",
    "\n",
    "    conv5 = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='SAME')(drop4)\n",
    "    conv5 = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='SAME')(conv5)\n",
    "    \n",
    "    conv5u = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='SAME')(conv5)\n",
    "    up6 = keras.layers.concatenate([conv5u, conv4], axis=3)\n",
    "    conv6 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(up6)\n",
    "    conv6 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(conv6)\n",
    "    \n",
    "    conv6u = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='SAME')(conv6)\n",
    "    up7 = keras.layers.concatenate([conv6u, conv3], axis=3)\n",
    "    conv7 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(up7)\n",
    "    conv7 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(conv7)\n",
    "    \n",
    "    conv7u = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='SAME')(conv7)\n",
    "    up8 = keras.layers.concatenate([conv7u, conv2], axis=3)\n",
    "    conv8 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(up8)\n",
    "    conv8 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(conv8)\n",
    "    \n",
    "    conv8u = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='SAME')(conv8)\n",
    "    up9 = keras.layers.concatenate([conv8u, conv1], axis=3)\n",
    "    conv9 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='SAME')(up9)\n",
    "    conv9 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='SAME')(conv9)\n",
    "\n",
    "    conv10 = keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    model.compile(optimizer=optimizer(lr=lr), loss=loss_metric, metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "sample_width = 128\n",
    "sample_height = 128\n",
    "\n",
    "inputs = keras.Input((sample_width, sample_height, 1))\n",
    "conv1 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='SAME')(inputs)\n",
    "conv1 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='SAME')(conv1)\n",
    "conv1 = tf.reshape(conv1, tf.shape(conv1))\n",
    "pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "drop1 = keras.layers.Dropout(0.5)(pool1)\n",
    "\n",
    "conv2 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(drop1)\n",
    "conv2 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(conv2)\n",
    "conv2 = tf.reshape(conv2, tf.shape(conv2))\n",
    "pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "drop2 = keras.layers.Dropout(0.5)(pool2)\n",
    "\n",
    "conv3 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(drop2)\n",
    "conv3 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(conv3)\n",
    "conv3 = tf.reshape(conv3, tf.shape(conv3))\n",
    "pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "drop3 = keras.layers.Dropout(0.3)(pool3)\n",
    "\n",
    "conv4 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(drop3)\n",
    "conv4 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(conv4)\n",
    "conv4 = tf.reshape(conv4, tf.shape(conv4))\n",
    "pool4 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "drop4 = keras.layers.Dropout(0.3)(pool4)\n",
    "\n",
    "conv5 = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='SAME')(drop4)\n",
    "conv5 = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='SAME')(conv5)\n",
    "conv5 = tf.reshape(conv5, tf.shape(conv5))\n",
    "\n",
    "conv5u = tf.keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='SAME')(conv5)\n",
    "conv5u = tf.reshape(conv5u, tf.shape(conv5u))\n",
    "up6 = keras.layers.concatenate([conv5u, conv4], axis=3)\n",
    "conv6 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(up6)\n",
    "conv6 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(conv6)\n",
    "conv6 = tf.reshape(conv6, tf.shape(conv6))\n",
    "\n",
    "conv6u = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='SAME')(conv6)\n",
    "conv6u = tf.reshape(conv6u, tf.shape(conv6u))\n",
    "up7 = keras.layers.concatenate([conv6u, conv3], axis=3)\n",
    "conv7 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(up7)\n",
    "conv7 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(conv7)\n",
    "conv7 = tf.reshape(conv7, tf.shape(conv7))\n",
    "\n",
    "conv7u = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='SAME')(conv7)\n",
    "conv7u = tf.reshape(conv7u, tf.shape(conv7u))\n",
    "up8 = keras.layers.concatenate([conv7u, conv2], axis=3)\n",
    "conv8 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(up8)\n",
    "conv8 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(conv8)\n",
    "conv8 = tf.reshape(conv8, tf.shape(conv8))\n",
    "\n",
    "conv8u = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='SAME')(conv8)\n",
    "conv8u = tf.reshape(conv8u, tf.shape(conv8u))\n",
    "up9 = keras.layers.concatenate([conv8u, conv1], axis=3)\n",
    "conv9 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='SAME')(up9)\n",
    "conv9 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='SAME')(conv9)\n",
    "conv9 = tf.reshape(conv9, tf.shape(conv9))\n",
    "\n",
    "conv10 = keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "conv10 = tf.reshape(conv10, tf.shape(conv10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/50425044/input-channels-does-not-match-filters-input-channels-tensorflow\n",
    "# w = tf.Variable(tf.random_normal([kernel_size, kernel_size, size_out, size_in], mean=0.0, stddev=0.125), name=\"W\")\n",
    "# w = tf.Variable(tf.random.normal([256,256,1, 1], mean=0.0, stddev=0.125), name=\"W\")\n",
    "w = tf.Variable([256,256,1, 1], name=\"W\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Reshape_4:0\", shape=(None, 128, 128, 32), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.reshape(conv1, tf.shape(conv1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 8, 8, 512) \n",
      " (None, 16, 16, 256)\n"
     ]
    }
   ],
   "source": [
    "print(conv5.get_shape(), \"\\n\",\n",
    "      conv4.get_shape())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'conv2d_transpose_21/BiasAdd:0' shape=(None, 16, 16, 256) dtype=float32>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=2, strides=(2, 2), padding='SAME')(conv5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_8/concat:0' shape=(None, 16, 16, 512) dtype=float32>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.layers.concatenate([conv5u, conv4], axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.conv2d_transpose(\n",
    "    conv5.get_shape(), \n",
    "    filters = [256,256,1,1], \n",
    "    output_shape= conv4.get_shape(), \n",
    "    strides=[1,2,2,1],\n",
    "    padding='SAME'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = tf.expand_dims(image,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Tensor.get_shape of <tf.Tensor 'conv2d_9/Relu:0' shape=(None, 8, 8, 512) dtype=float32>> \n",
      " <bound method Tensor.get_shape of <tf.Tensor 'conv2d_7/Relu:0' shape=(None, 16, 16, 256) dtype=float32>>\n"
     ]
    }
   ],
   "source": [
    "print(conv5.get_shape, \"\\n\",\n",
    "      conv4.get_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'ndims' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c56538cc09f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mfoo1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mconv1W\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfoo1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mconv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m512\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv1W\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'SAME'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mconv1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconv2d_v2\u001b[1;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[0;32m   2156\u001b[0m   \"\"\"\n\u001b[0;32m   2157\u001b[0m   \u001b[1;31m# pylint: enable=line-too-long\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2158\u001b[1;33m   return conv2d(input,  # pylint: disable=redefined-builtin\n\u001b[0m\u001b[0;32m   2159\u001b[0m                 \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2160\u001b[0m                 \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[1;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[0;32m   2259\u001b[0m     \u001b[0mndims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ndims\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2260\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mndims\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mndims\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2261\u001b[1;33m   \u001b[1;32mif\u001b[0m \u001b[0mndims\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2262\u001b[0m     \u001b[1;31m# We avoid calling squeeze_batch_dims to reduce extra python function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2263\u001b[0m     \u001b[1;31m# call slowdown in eager mode.  This branch doesn't require reshapes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'ndims' referenced before assignment"
     ]
    }
   ],
   "source": [
    "stride = [1,1,1,1]\n",
    "foo1 = tf.random.normal([4,4,3,20])\n",
    "conv1W = tf.Variable(foo1)\n",
    "conv1 = tf.nn.conv2d(input, conv1W, strides=stride, padding='SAME')\n",
    "conv1 = tf.nn.relu(conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deconv1 = tf.nn.conv2d_transpose(conv1, conv1W, output_shape=[batch_size,output_height, output_width, output_channels],strides=stride)\n",
    "res = tf.nn.relu(deconv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.Variable([1,256,256,1]).get_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[1,256,256,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = [256,256,1,1]\n",
    "W_upconv = tf.compat.v1.get_variable (\"w\", shape=shape, \n",
    "                                      dtype=tf.float32,\n",
    "                                      initializer=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upconvolution (input, output_channel_size, filter_size_h, filter_size_w,\n",
    "                   stride_h, stride_w, init_w, init_b, layer_name, \n",
    "                   dtype=tf.float32, data_format=\"NHWC\", padding='VALID'):\n",
    "    with tf.variable_scope(layer_name):\n",
    "      #calculation of the output_shape:\n",
    "      if data_format == \"NHWC\":\n",
    "        input_channel_size = input.get_shape().as_list()[3]\n",
    "        input_size_h = input.get_shape().as_list()[1]\n",
    "        input_size_w = input.get_shape().as_list()[2]\n",
    "        stride_shape = [1, stride_h, stride_w, 1]\n",
    "        if padding == 'VALID':\n",
    "          output_size_h = (input_size_h - 1)*stride_h + filter_size_h\n",
    "          output_size_w = (input_size_w - 1)*stride_w + filter_size_w\n",
    "        elif padding == 'SAME':\n",
    "          output_size_h = (input_size_h - 1)*stride_h + 1\n",
    "          output_size_w = (input_size_w - 1)*stride_w + 1\n",
    "        else:\n",
    "          raise ValueError(\"unknown padding\")\n",
    "        output_shape = tf.stack([tf.shape(input)[0], \n",
    "                                output_size_h, output_size_w, \n",
    "                                output_channel_size])\n",
    "      elif data_format == \"NCHW\":\n",
    "        input_channel_size = input.get_shape().as_list()[1]\n",
    "        input_size_h = input.get_shape().as_list()[2]\n",
    "        input_size_w = input.get_shape().as_list()[3]\n",
    "        stride_shape = [1, 1, stride_h, stride_w]\n",
    "        if padding == 'VALID':\n",
    "          output_size_h = (input_size_h - 1)*stride_h + filter_size_h\n",
    "          output_size_w = (input_size_w - 1)*stride_w + filter_size_w\n",
    "        elif padding == 'SAME':\n",
    "          output_size_h = (input_size_h - 1)*stride_h + 1\n",
    "          output_size_w = (input_size_w - 1)*stride_w + 1\n",
    "        else:\n",
    "          raise ValueError(\"unknown padding\")\n",
    "        output_shape = tf.stack([tf.shape(input)[0], \n",
    "                                output_channel_size, \n",
    "                                output_size_h, output_size_w])\n",
    "      else:\n",
    "        raise ValueError(\"unknown data_format\")\n",
    "\n",
    "      #creating weights:\n",
    "      shape = [filter_size_h, filter_size_w, \n",
    "               output_channel_size, input_channel_size]\n",
    "      W_upconv = tf.get_variable(\"w\", shape=shape, dtype=dtype,\n",
    "                                 initializer=init_w)\n",
    "      \n",
    "      shape=[output_channel_size]\n",
    "      b_upconv = tf.get_variable(\"b\", shape=shape, dtype=dtype, \n",
    "                                 initializer=init_b)\n",
    "      \n",
    "      upconv = tf.nn.conv2d_transpose(input, W_upconv, output_shape, stride_shape,\n",
    "                                      padding=padding,\n",
    "                                      data_format=data_format)\n",
    "      output = tf.nn.bias_add(upconv, b_upconv, data_format=data_format)\n",
    "      \n",
    "      #Now output.get_shape() is equal (?,?,?,?) which can become a problem in the \n",
    "      #next layers. This can be repaired by reshaping the tensor to its shape:\n",
    "      output = tf.reshape(output, output_shape)\n",
    "      #now the shape is back to (?, H, W, C) or (?, C, H, W)\n",
    "      \n",
    "      return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upconvolution (input, output_channel_size, filter_size_h, filter_size_w,\n",
    "                   stride_h, stride_w, init_w, init_b, layer_name, \n",
    "                   dtype=tf.float32, data_format=\"NHWC\", padding='VALID')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
