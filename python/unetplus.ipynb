{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmentation_models import Unet, Nestnet, Xnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage.measure\n",
    "# import pydicom\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from keras import backend as K\n",
    "import keras\n",
    "# from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, Input\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.gray()\n",
    "os.chdir('C:/Users/span/Documents/CNN/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "#     horizontal_flip=True\n",
    ")\n",
    "        \n",
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 472 images belonging to 1 classes.\n",
      "Found 472 images belonging to 1 classes.\n",
      "Found 203 images belonging to 1 classes.\n",
      "Found 203 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# only 0 and 255 in seg\n",
    "subfolder1 = \"_0255/\"\n",
    "# subfolder1 = \"/\"\n",
    "\n",
    "path1 = \"02_data/train_image\"+subfolder1\n",
    "path2 = \"02_data/train_mask\"+subfolder1\n",
    "path3 = \"02_data/val_image\"+subfolder1\n",
    "path4 = \"02_data/val_mask\"+subfolder1\n",
    "\n",
    "# # scale to 255 in val\n",
    "# path1 = \"02_data/train_image_re255/\"\n",
    "# path2 = \"02_data/train_mask_re255/\"\n",
    "# path3 = \"02_data/val_image_re255/\"\n",
    "# path4 = \"02_data/val_mask_re255/\"\n",
    "\n",
    "batch_size1 = 16\n",
    "\n",
    "train_image_generator = train_datagen.flow_from_directory(\n",
    "    path1,\n",
    "#     color_mode = \"grayscale\",\n",
    "    batch_size = batch_size1 #NORMALLY 4/8/16/32\n",
    ")\n",
    "\n",
    "train_mask_generator = train_datagen.flow_from_directory(\n",
    "    path2,\n",
    "#     color_mode = \"grayscale\",\n",
    "    batch_size = batch_size1 #NORMALLY 4/8/16/32\n",
    ")\n",
    "\n",
    "val_image_generator = val_datagen.flow_from_directory(\n",
    "    path3,\n",
    "#     color_mode = \"grayscale\",\n",
    "    batch_size = batch_size1 #NORMALLY 4/8/16/32\n",
    ")\n",
    "\n",
    "\n",
    "val_mask_generator = val_datagen.flow_from_directory(\n",
    "    path4,\n",
    "#     color_mode = \"grayscale\",\n",
    "    batch_size = batch_size1 #NORMALLY 4/8/16/32\n",
    ")\n",
    "\n",
    "train_generator = zip(train_image_generator, train_mask_generator)\n",
    "val_generator = zip(val_image_generator, val_mask_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't set the attribute \"name\", likely because it conflicts with an existing read-only @property of the object. Please choose a different name.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-n-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   2761\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2762\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAutoTrackable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2763\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: can't set attribute",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-c7645a779ef3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackbone_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'resnet50'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'imagenet'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_block_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'transpose'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# build UNet++\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# model = Unet(backbone_name='resnet50', encoder_weights='imagenet', decoder_block_type='transpose') # build U-Net\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# model = NestNet(backbone_name='resnet50', encoder_weights='imagenet', decoder_block_type='transpose') # build DLA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'binary_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-n-gpu\\lib\\site-packages\\segmentation_models\\xnet\\model.py\u001b[0m in \u001b[0;36mXnet\u001b[1;34m(backbone_name, input_shape, input_tensor, encoder_weights, freeze_encoder, skip_connections, decoder_block_type, decoder_filters, decoder_use_batchnorm, n_upsample_blocks, upsample_rates, classes, activation)\u001b[0m\n\u001b[0;32m     84\u001b[0m                             \u001b[0minput_tensor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                             \u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoder_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m                             include_top=False)\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mskip_connections\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'default'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-n-gpu\\lib\\site-packages\\segmentation_models\\backbones\\backbones.py\u001b[0m in \u001b[0;36mget_backbone\u001b[1;34m(name, *args, **kwargs)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_backbone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbackbones\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-n-gpu\\lib\\site-packages\\segmentation_models\\backbones\\classification_models\\classification_models\\resnet\\models.py\u001b[0m in \u001b[0;36mResNet50\u001b[1;34m(input_shape, input_tensor, weights, classes, include_top)\u001b[0m\n\u001b[0;32m     38\u001b[0m                          \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m                          include_top=include_top)\n\u001b[1;32m---> 40\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'resnet50'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-n-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m    338\u001b[0m                          ' Always start with this line.'), None)\n\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m     \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mgeneric_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-n-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   2765\u001b[0m             ('Can\\'t set the attribute \"{}\", likely because it conflicts with '\n\u001b[0;32m   2766\u001b[0m              \u001b[1;34m'an existing read-only @property of the object. Please choose a '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2767\u001b[1;33m              'different name.').format(name))\n\u001b[0m\u001b[0;32m   2768\u001b[0m       \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2769\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: Can't set the attribute \"name\", likely because it conflicts with an existing read-only @property of the object. Please choose a different name."
     ]
    }
   ],
   "source": [
    "model = Xnet(backbone_name='resnet50', encoder_weights='imagenet', decoder_block_type='transpose') # build UNet++\n",
    "# model = Unet(backbone_name='resnet50', encoder_weights='imagenet', decoder_block_type='transpose') # build U-Net\n",
    "# model = NestNet(backbone_name='resnet50', encoder_weights='imagenet', decoder_block_type='transpose') # build DLA\n",
    "\n",
    "model.compile('Adam', 'binary_crossentropy', ['binary_accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "model.fit(train_generator, val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not necessarily working\n",
    "# add layer\n",
    "from keras import backend as K\n",
    "import keras\n",
    "# from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, Input\n",
    "import tensorflow as tf\n",
    "\n",
    "num_gpus = 2\n",
    "def get_model1(optimizer, loss_metric, metrics, lr=1e-3):\n",
    "    cross_tower_ops = tf.distribute.HierarchicalCopyAllReduce(num_packs=num_gpus)\n",
    "    strategy = tf.distribute.MirroredStrategy(cross_device_ops=cross_tower_ops)\n",
    "#     strategy = tf.distribute.MirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        inputs = keras.Input((sample_width, sample_height, 1))\n",
    "    \n",
    "        conv0 = keras.layers.Conv2D(16, (3, 3), activation='relu', padding='SAME')(inputs)\n",
    "        conv0 = keras.layers.Conv2D(16, (3, 3), activation='relu', padding='SAME')(conv0)\n",
    "        conv0 = tf.reshape(conv0, tf.shape(conv0))\n",
    "        pool0 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv0)\n",
    "        drop0 = keras.layers.Dropout(0.5)(pool0)\n",
    "    \n",
    "        conv1 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='SAME')(drop0)\n",
    "        conv1 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='SAME')(conv1)\n",
    "        conv1 = tf.reshape(conv1, tf.shape(conv1))\n",
    "        pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        drop1 = keras.layers.Dropout(0.5)(pool1)\n",
    "\n",
    "        conv2 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(drop1)\n",
    "        conv2 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(conv2)\n",
    "        conv2 = tf.reshape(conv2, tf.shape(conv2))\n",
    "        pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "        drop2 = keras.layers.Dropout(0.5)(pool2)\n",
    "\n",
    "        conv3 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(drop2)\n",
    "        conv3 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(conv3)\n",
    "        conv3 = tf.reshape(conv3, tf.shape(conv3))\n",
    "        pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "        drop3 = keras.layers.Dropout(0.3)(pool3)\n",
    "\n",
    "        conv4 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(drop3)\n",
    "        conv4 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(conv4)\n",
    "        conv4 = tf.reshape(conv4, tf.shape(conv4))\n",
    "        pool4 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "        drop4 = keras.layers.Dropout(0.3)(pool4)\n",
    "        \n",
    "        conv5 = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='SAME')(drop4)\n",
    "        conv5 = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='SAME')(conv5)\n",
    "        conv5 = tf.reshape(conv5, tf.shape(conv5))\n",
    "        pool5 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv5)\n",
    "        drop5 = keras.layers.Dropout(0.3)(pool5)\n",
    "\n",
    "        convc5 = keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='SAME')(drop5)\n",
    "        convc5 = keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='SAME')(convc5)\n",
    "        convc5 = tf.reshape(convc5, tf.shape(convc5))\n",
    "        \n",
    "        convc5u = tf.keras.layers.Conv2DTranspose(filters=512, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(convc5)\n",
    "        convc5u = tf.reshape(convc5u, tf.shape(convc5u))\n",
    "        upc6 = keras.layers.concatenate([convc5u, conv5], axis=3)\n",
    "        convc6 = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='SAME')(upc6)\n",
    "        convc6 = keras.layers.Conv2D(512, (3, 3), activation='relu', padding='SAME')(convc6)\n",
    "        convc6 = tf.reshape(convc6, tf.shape(convc6))\n",
    "    \n",
    "        conv5u = tf.keras.layers.Conv2DTranspose(filters=256, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(convc6)\n",
    "        conv5u = tf.reshape(conv5u, tf.shape(conv5u))\n",
    "        up6 = keras.layers.concatenate([conv5u, conv4], axis=3)\n",
    "        conv6 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(up6)\n",
    "        conv6 = keras.layers.Conv2D(256, (3, 3), activation='relu', padding='SAME')(conv6)\n",
    "        conv6 = tf.reshape(conv6, tf.shape(conv6))\n",
    "    \n",
    "        conv6u = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(conv6)\n",
    "        conv6u = tf.reshape(conv6u, tf.shape(conv6u))\n",
    "        up7 = keras.layers.concatenate([conv6u, conv3], axis=3)\n",
    "        conv7 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(up7)\n",
    "        conv7 = keras.layers.Conv2D(128, (3, 3), activation='relu', padding='SAME')(conv7)\n",
    "        conv7 = tf.reshape(conv7, tf.shape(conv7))\n",
    "    \n",
    "        conv7u = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(conv7)\n",
    "        conv7u = tf.reshape(conv7u, tf.shape(conv7u))\n",
    "        up8 = keras.layers.concatenate([conv7u, conv2], axis=3)\n",
    "        conv8 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(up8)\n",
    "        conv8 = keras.layers.Conv2D(64, (3, 3), activation='relu', padding='SAME')(conv8)\n",
    "        conv8 = tf.reshape(conv8, tf.shape(conv8))\n",
    "    \n",
    "        conv8u = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(conv8)\n",
    "        conv8u = tf.reshape(conv8u, tf.shape(conv8u))\n",
    "        up9 = keras.layers.concatenate([conv8u, conv1], axis=3)\n",
    "        conv9 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='SAME')(up9)\n",
    "        conv9 = keras.layers.Conv2D(32, (3, 3), activation='relu', padding='SAME')(conv9)\n",
    "        conv9 = tf.reshape(conv9, tf.shape(conv9))\n",
    "    \n",
    "        conv9u = tf.keras.layers.Conv2DTranspose(filters=16, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(conv9)\n",
    "        conv9u = tf.reshape(conv9u, tf.shape(conv9u))\n",
    "        up10 = keras.layers.concatenate([conv9u, conv0], axis=3)\n",
    "        conv10 = keras.layers.Conv2D(16, (3, 3), activation='relu', padding='SAME')(up10)\n",
    "        conv10 = keras.layers.Conv2D(16, (3, 3), activation='relu', padding='SAME')(conv10)\n",
    "        conv10 = tf.reshape(conv10, tf.shape(conv10))\n",
    "\n",
    "        conv11 = keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(conv10)\n",
    "        conv11 = tf.reshape(conv11, tf.shape(conv11))\n",
    "\n",
    "        model = keras.Model(inputs=[inputs], outputs=[conv11])\n",
    "\n",
    "        model.compile(optimizer=optimizer(lr=lr), loss=loss_metric, metrics=metrics)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add layer\n",
    "sample_width = 256\n",
    "sample_height = 256\n",
    "\n",
    "# tf.keras.optimizers.SGD\n",
    "# tf.keras.optimizers.Adam\n",
    "\n",
    "# dice_coef_loss\n",
    "# tf.keras.losses.binary_crossentropy\n",
    "# tf.keras.losses.BinaryCrossentropy()\n",
    "\n",
    "model = get_model1(optimizer=tf.keras.optimizers.Adam,\n",
    "                   loss_metric=dice_coef_loss, metrics=['AUC', dice_coef],  #dice_coef, 'binary_accuracy'\n",
    "                   lr=1e-6\n",
    "                  )\n",
    "# 'AUC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import keras\n",
    "# from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout, Input\n",
    "import tensorflow as tf\n",
    "\n",
    "sample_width = 512\n",
    "sample_height = 512\n",
    "n_filters = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256, 256, 16)\n"
     ]
    }
   ],
   "source": [
    "inputs = keras.Input((sample_width, sample_height, 1))\n",
    "conv1 = keras.layers.Conv2D(n_filters*2, (3, 3), activation='relu', padding='SAME')(inputs)\n",
    "conv1 = keras.layers.Conv2D(n_filters*2, (3, 3), activation='relu', padding='SAME')(conv1)\n",
    "conv1 = tf.reshape(conv1, tf.shape(conv1))\n",
    "pool1 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "drop1 = keras.layers.Dropout(0.2)(pool1)\n",
    "\n",
    "print(drop1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 128, 128, 32)\n"
     ]
    }
   ],
   "source": [
    "conv2 = keras.layers.Conv2D(n_filters*4, (3, 3), activation='relu', padding='SAME')(drop1)\n",
    "conv2 = keras.layers.Conv2D(n_filters*4, (3, 3), activation='relu', padding='SAME')(conv2)\n",
    "conv2 = tf.reshape(conv2, tf.shape(conv2))\n",
    "pool2 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "drop2 = keras.layers.Dropout(0.2)(pool2)\n",
    "\n",
    "print(drop2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 64, 64)\n"
     ]
    }
   ],
   "source": [
    "conv3 = keras.layers.Conv2D(n_filters*8, (3, 3), activation='relu', padding='SAME')(drop2)\n",
    "conv3 = keras.layers.Conv2D(n_filters*8, (3, 3), activation='relu', padding='SAME')(conv3)\n",
    "conv3 = tf.reshape(conv3, tf.shape(conv3))\n",
    "pool3 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "drop3 = keras.layers.Dropout(0.3)(pool3)\n",
    "\n",
    "print(drop3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 32, 32, 128)\n"
     ]
    }
   ],
   "source": [
    "conv4 = keras.layers.Conv2D(n_filters*16, (3, 3), activation='relu', padding='SAME')(drop3)\n",
    "conv4 = keras.layers.Conv2D(n_filters*16, (3, 3), activation='relu', padding='SAME')(conv4)\n",
    "conv4 = tf.reshape(conv4, tf.shape(conv4))\n",
    "pool4 = keras.layers.MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "drop4 = keras.layers.Dropout(0.3)(pool4)\n",
    "\n",
    "print(drop4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 32, 32, 256)\n"
     ]
    }
   ],
   "source": [
    "conv5 = keras.layers.Conv2D(n_filters*32, (3, 3), activation='relu', padding='SAME')(drop4)\n",
    "conv5 = keras.layers.Conv2D(n_filters*32, (3, 3), activation='relu', padding='SAME')(conv5)\n",
    "conv5 = tf.reshape(conv5, tf.shape(conv5))\n",
    "    \n",
    "print(conv5.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 64, 128) (None, 64, 64, 128) \n",
      " (None, 64, 64, 128)\n"
     ]
    }
   ],
   "source": [
    "conv5u = tf.keras.layers.Conv2DTranspose(filters=n_filters*16, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(conv5)\n",
    "conv5u = tf.reshape(conv5u, tf.shape(conv5u))\n",
    "up6 = keras.layers.concatenate([conv5u, conv4], axis=3)\n",
    "up6 = keras.layers.Dropout(0.2)(up6)\n",
    "conv6 = keras.layers.Conv2D(n_filters*16, (3, 3), activation='relu', padding='SAME')(up6)\n",
    "conv6 = keras.layers.Conv2D(n_filters*16, (3, 3), activation='relu', padding='SAME')(conv6)\n",
    "conv6 = tf.reshape(conv6, tf.shape(conv6))\n",
    "    \n",
    "print(conv5u.shape, conv4.shape, \"\\n\", conv6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 64, 64, 128) (None, 64, 64, 128) \n",
      " (None, 64, 64, 128)\n"
     ]
    }
   ],
   "source": [
    "conv5u = keras.layers.Conv2D(n_filters*16, 2, activation = 'relu', padding = 'same')(tf.keras.layers.UpSampling2D(size = (2,2))(conv5))\n",
    "conv5u = tf.reshape(conv5u, tf.shape(conv5u))\n",
    "up6 = keras.layers.concatenate([conv5u, conv4], axis=3)\n",
    "up6 = keras.layers.Dropout(0.2)(up6)\n",
    "conv6 = keras.layers.Conv2D(n_filters*16, (3, 3), activation='relu', padding='SAME')(up6)\n",
    "conv6 = keras.layers.Conv2D(n_filters*16, (3, 3), activation='relu', padding='SAME')(conv6)\n",
    "conv6 = tf.reshape(conv6, tf.shape(conv6))\n",
    "print(conv5u.shape, conv4.shape, \"\\n\", conv6.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 128, 128, 64) (None, 128, 128, 64) \n",
      " (None, 128, 128, 64)\n"
     ]
    }
   ],
   "source": [
    "conv6u = tf.keras.layers.Conv2DTranspose(filters=n_filters*8, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(conv6)\n",
    "conv6u = tf.reshape(conv6u, tf.shape(conv6u))\n",
    "up7 = keras.layers.concatenate([conv6u, conv3], axis=3)\n",
    "up7 = keras.layers.Dropout(0.2)(up7)\n",
    "conv7 = keras.layers.Conv2D(n_filters*8, (3, 3), activation='relu', padding='SAME')(up7)\n",
    "conv7 = keras.layers.Conv2D(n_filters*8, (3, 3), activation='relu', padding='SAME')(conv7)\n",
    "conv7 = tf.reshape(conv7, tf.shape(conv7))\n",
    "    \n",
    "print(conv6u.shape, conv3.shape, \"\\n\", conv7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256, 256, 32) (None, 256, 256, 32) \n",
      " (None, 256, 256, 32)\n"
     ]
    }
   ],
   "source": [
    "conv7u = tf.keras.layers.Conv2DTranspose(filters=n_filters*4, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(conv7)\n",
    "conv7u = tf.reshape(conv7u, tf.shape(conv7u))\n",
    "up8 = keras.layers.concatenate([conv7u, conv2], axis=3)\n",
    "up8 = keras.layers.Dropout(0.2)(up8)\n",
    "conv8 = keras.layers.Conv2D(n_filters*4, (3, 3), activation='relu', padding='SAME')(up8)\n",
    "conv8 = keras.layers.Conv2D(n_filters*4, (3, 3), activation='relu', padding='SAME')(conv8)\n",
    "conv8 = tf.reshape(conv8, tf.shape(conv8))\n",
    "    \n",
    "print(conv7u.shape, conv2.shape, \"\\n\", conv8.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256, 256, 32) (None, 256, 256, 32) \n",
      " (None, 256, 256, 32)\n"
     ]
    }
   ],
   "source": [
    "conv8u = tf.keras.layers.Conv2DTranspose(filters=n_filters*2, kernel_size=(2, 2), strides=(2, 2), padding='SAME')(conv8)\n",
    "conv8u = tf.reshape(conv8u, tf.shape(conv8u))\n",
    "up9 = keras.layers.concatenate([conv8u, conv1], axis=3)\n",
    "up9 = keras.layers.Dropout(0.2)(up9)\n",
    "conv9 = keras.layers.Conv2D(n_filters*2, (3, 3), activation='relu', padding='SAME')(up9)\n",
    "conv9 = keras.layers.Conv2D(n_filters*2, (3, 3), activation='relu', padding='SAME')(conv9)\n",
    "conv9 = tf.reshape(conv9, tf.shape(conv9))\n",
    "\n",
    "print(conv8u.shape, conv1.shape, \"\\n\", conv9.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256, 256, 1)\n"
     ]
    }
   ],
   "source": [
    "conv10 = keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "conv10 = tf.reshape(conv10, tf.shape(conv10))\n",
    "print(conv10.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
